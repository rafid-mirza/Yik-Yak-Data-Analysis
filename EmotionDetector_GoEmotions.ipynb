{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1Jua0D_Jsbd"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.11.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow_datasets"
      ],
      "metadata": {
        "id": "oe2285qyKzW8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install curl gnupg"
      ],
      "metadata": {
        "id": "mgyJYlpRK6gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -"
      ],
      "metadata": {
        "id": "dj6pkxwbK9gT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list"
      ],
      "metadata": {
        "id": "TIcJQgBgLAki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update"
      ],
      "metadata": {
        "id": "oVr95L3ULEXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install bazel=5.4.0"
      ],
      "metadata": {
        "id": "GGIS1U09LIV9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://www.github.com/tensorflow/models"
      ],
      "metadata": {
        "id": "fDmrp1erLMRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!models/research/seq_flow_lite/demo/colab/setup_workspace.sh"
      ],
      "metadata": {
        "id": "eBsXnUHoLWkq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install models/research/seq_flow_lite"
      ],
      "metadata": {
        "id": "06zjbkFhLYkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf models/research/seq_flow_lite/tf_ops"
      ],
      "metadata": {
        "id": "kaSMQg3qLbOc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf models/research/seq_flow_list/tflite_ops"
      ],
      "metadata": {
        "id": "_cQIRK2DRKLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models/research/seq_flow_lite"
      ],
      "metadata": {
        "id": "tvY4L2hVRSGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "XVx5yOZ7L5ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "9vuvbE1VL6YA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tfds.load('goemotions', split='train')"
      ],
      "metadata": {
        "id": "bn_6QC99L9xq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for element in ds.take(5):\n",
        "  print(element)"
      ],
      "metadata": {
        "id": "Dv3_4qcFMD4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS = [\n",
        "    'admiration',\n",
        "    'amusement',\n",
        "    'anger',\n",
        "    'annoyance',\n",
        "    'approval',\n",
        "    'caring',\n",
        "    'confusion',\n",
        "    'curiosity',\n",
        "    'desire',\n",
        "    'disappointment',\n",
        "    'disapproval',\n",
        "    'disgust',\n",
        "    'embarrassment',\n",
        "    'excitement',\n",
        "    'fear',\n",
        "    'gratitude',\n",
        "    'grief',\n",
        "    'joy',\n",
        "    'love',\n",
        "    'nervousness',\n",
        "    'optimism',\n",
        "    'pride',\n",
        "    'realization',\n",
        "    'relief',\n",
        "    'remorse',\n",
        "    'sadness',\n",
        "    'surprise',\n",
        "    'neutral',\n",
        "]\n"
      ],
      "metadata": {
        "id": "Z9p-r7X1MJYC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'name': 'models.prado',\n",
        "    'batch_size': 1024,\n",
        "    'train_steps': 10000,\n",
        "    'learning_rate': 0.0006,\n",
        "    'learning_rate_decay_steps': 340,\n",
        "    'learning_rate_decay_rate': 0.7,\n",
        "}"
      ],
      "metadata": {
        "id": "vvh-skz2MOkr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG['save_checkpoints_steps'] = int(CONFIG['train_steps'] / 10)"
      ],
      "metadata": {
        "id": "M4vnqi9wMRBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_CONFIG = {\n",
        "    'labels': LABELS,\n",
        "    'multilabel': True,\n",
        "    'quantize': False,\n",
        "    'max_seq_len': 128,\n",
        "    'max_seq_len_inference': 128,\n",
        "    'exclude_nonalphaspace_unicodes': False,\n",
        "    'split_on_space': True,\n",
        "    'embedding_regularizer_scale': 0.035,\n",
        "    'embedding_size': 64,\n",
        "    'bigram_channels': 64,\n",
        "    'trigram_channels': 64,\n",
        "    'feature_size': 512,\n",
        "    'network_regularizer_scale': 0.0001,\n",
        "    'keep_prob': 0.5,\n",
        "    'word_novelty_bits': 0,\n",
        "    'doc_size_levels': 0,\n",
        "    'add_bos_tag': False,\n",
        "    'add_eos_tag': False,\n",
        "    'pre_logits_fc_layers': [],\n",
        "    'text_distortion_probability': 0.0,\n",
        "}"
      ],
      "metadata": {
        "id": "O-eA_vo4MTZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG['model_config'] = MODEL_CONFIG"
      ],
      "metadata": {
        "id": "xhJ4kYgzMc-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install layers"
      ],
      "metadata": {
        "id": "692p7FxAN1TG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "Ex5qxNxFOrVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from layers import base_layers\n",
        "from layers import projection_layers\n",
        "\n",
        "def build_dataset(mode, inspect=False):\n",
        "  if mode == base_layers.TRAIN:\n",
        "    split = 'train'\n",
        "    count = None\n",
        "  elif mode == base_layers.EVAL:\n",
        "    split = 'test'\n",
        "    count = 1\n",
        "  else:\n",
        "    raise ValueError('mode={}, must be TRAIN or EVAL'.format(mode))\n",
        "\n",
        "  batch_size = CONFIG['batch_size']\n",
        "  if inspect:\n",
        "    batch_size = 1\n",
        "\n",
        "  # Convert examples from their dataset format into the model format.\n",
        "  def process_input(features):\n",
        "    # Generate the projection for each comment_text input.  The final tensor\n",
        "    # will have the shape [batch_size, number of tokens, feature size].\n",
        "    # Additionally, we generate a tensor containing the number of tokens for\n",
        "    # each comment_text (seq_length).  This is needed because the projection\n",
        "    # tensor is a full tensor, and we are not using EOS tokens.\n",
        "    text = features['comment_text']\n",
        "    text = tf.reshape(text, [batch_size])\n",
        "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
        "    projection, seq_length = projection_layer(text)\n",
        "\n",
        "    # Convert the labels into an indicator tensor, using the LABELS indices.\n",
        "    label = tf.stack([features[label] for label in LABELS], axis=-1)\n",
        "    label = tf.cast(label, tf.float32)\n",
        "    label = tf.reshape(label, [batch_size, len(LABELS)])\n",
        "\n",
        "    model_features = ({'projection': projection, 'sequence_length': seq_length}, label)\n",
        "\n",
        "    if inspect:\n",
        "      model_features = (model_features[0], model_features[1], features)\n",
        "\n",
        "    return model_features\n",
        "\n",
        "  ds = tfds.load('goemotions', split=split)\n",
        "  ds = ds.repeat(count=count)\n",
        "  ds = ds.shuffle(buffer_size=batch_size * 2)\n",
        "  ds = ds.batch(batch_size, drop_remainder=True)\n",
        "  ds = ds.map(process_input,\n",
        "              num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
        "              deterministic=False)\n",
        "  ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "  return ds\n",
        "\n",
        "train_dataset = build_dataset(base_layers.TRAIN)\n",
        "test_dataset = build_dataset(base_layers.EVAL)\n",
        "inspect_dataset = build_dataset(base_layers.TRAIN, inspect=True)"
      ],
      "metadata": {
        "id": "UhGN-H3dMfsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from models import prado\n",
        "\n",
        "def build_model(mode):\n",
        "  # First we define our inputs.\n",
        "  inputs = []\n",
        "  if mode == base_layers.TRAIN or mode == base_layers.EVAL:\n",
        "    # For TRAIN and EVAL, we'll be getting dataset examples,\n",
        "    # so we'll get projections and sequence_lengths.\n",
        "    projection = tf.keras.Input(\n",
        "        shape=(MODEL_CONFIG['max_seq_len'], MODEL_CONFIG['feature_size']),\n",
        "        name='projection',\n",
        "        dtype='float32')\n",
        "\n",
        "    sequence_length = tf.keras.Input(\n",
        "        shape=(), name='sequence_length', dtype='float32')\n",
        "    inputs = [projection, sequence_length]\n",
        "  else:\n",
        "    # Otherwise, we get string inputs which we need to project.\n",
        "    input = tf.keras.Input(shape=(), name='input', dtype='string')\n",
        "    projection_layer = projection_layers.ProjectionLayer(MODEL_CONFIG, mode)\n",
        "    projection, sequence_length = projection_layer(input)\n",
        "    inputs = [input]\n",
        "\n",
        "  # Next we add the model layer.\n",
        "  model_layer = prado.Encoder(MODEL_CONFIG, mode)\n",
        "  logits = model_layer(projection, sequence_length)\n",
        "\n",
        "  # Finally we add an activation layer.\n",
        "  if MODEL_CONFIG['multilabel']:\n",
        "    activation = tf.keras.layers.Activation('sigmoid', name='predictions')\n",
        "  else:\n",
        "    activation = tf.keras.layers.Activation('softmax', name='predictions')\n",
        "  predictions = activation(logits)\n",
        "\n",
        "  model = tf.keras.Model(\n",
        "      inputs=inputs,\n",
        "      outputs=[predictions])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "zSuk8E3DRgMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf model\n",
        "\n",
        "model = build_model(base_layers.TRAIN)\n",
        "\n",
        "# Create the optimizer.\n",
        "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=CONFIG['learning_rate'],\n",
        "    decay_rate=CONFIG['learning_rate_decay_rate'],\n",
        "    decay_steps=CONFIG['learning_rate_decay_steps'],\n",
        "    staircase=True)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "# Define the loss function.\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss)\n",
        "\n",
        "epochs = int(CONFIG['train_steps'] / CONFIG['save_checkpoints_steps'])\n",
        "model.fit(\n",
        "    x=train_dataset,\n",
        "    epochs=epochs,\n",
        "    validation_data=test_dataset,\n",
        "    steps_per_epoch=CONFIG['save_checkpoints_steps'])\n",
        "\n",
        "model.save_weights('model/model_checkpoint')"
      ],
      "metadata": {
        "id": "87sgczsFRqDV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(base_layers.EVAL)\n",
        "\n",
        "# Define metrics over each category.\n",
        "metrics = []\n",
        "for i, label in enumerate(LABELS):\n",
        "  metric = tf.keras.metrics.Precision(\n",
        "      thresholds=[0.5],\n",
        "      class_id=i,\n",
        "      name='precision@0.5/{}'.format(label))\n",
        "  metrics.append(metric)\n",
        "  metric = tf.keras.metrics.Recall(\n",
        "      thresholds=[0.5],\n",
        "      class_id=i,\n",
        "      name='recall@0.5/{}'.format(label))\n",
        "  metrics.append(metric)\n",
        "\n",
        "# Define metrics over the entire task.\n",
        "metric = tf.keras.metrics.Precision(thresholds=[0.5], name='precision@0.5/all')\n",
        "metrics.append(metric)\n",
        "metric = tf.keras.metrics.Recall(thresholds=[0.5], name='recall@0.5/all')\n",
        "metrics.append(metric)\n",
        "\n",
        "model.compile(metrics=metrics)\n",
        "model.load_weights('model/model_checkpoint')\n",
        "result = model.evaluate(x=test_dataset, return_dict=True)\n"
      ],
      "metadata": {
        "id": "2IaZeK8iRz_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for label in LABELS:\n",
        "  precision_key = 'precision@0.5/{}'.format(label)\n",
        "  recall_key = 'recall@0.5/{}'.format(label)\n",
        "  if precision_key in result and recall_key in result:\n",
        "    print('{}: (precision@0.5: {}, recall@0.5: {})'.format(\n",
        "        label, result[precision_key], result[recall_key]))\n",
        "\n",
        "precision_key = 'precision@0.5/all'\n",
        "recall_key = 'recall@0.5/all'\n",
        "if precision_key in result and recall_key in result:\n",
        "  print('all: (precision@0.5: {}, recall@0.5: {})'.format(\n",
        "      result[precision_key], result[recall_key]))"
      ],
      "metadata": {
        "id": "PHT1QcZVT5QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EMOTION_MAP = {\n",
        "    'admiration': 'admiration',\n",
        "    'amusement': 'amusement',\n",
        "    'anger': 'anger',\n",
        "    'annoyance': 'annoyance',\n",
        "    'approval': 'approval',\n",
        "    'caring': 'caring',\n",
        "    'confusion': 'confusion',\n",
        "    'curiosity': 'curiosity',\n",
        "    'desire': 'desire',\n",
        "    'disappointment': 'disappointment',\n",
        "    'disapproval': 'disapproval',\n",
        "    'disgust': 'disgust',\n",
        "    'embarrassment': 'embarrassment',\n",
        "    'excitement': 'excitement',\n",
        "    'fear': 'fear',\n",
        "    'gratitude': 'gratitude',\n",
        "    'grief': 'grief',\n",
        "    'joy': 'joy',\n",
        "    'love': 'love',\n",
        "    'nervousness': 'nervousness',\n",
        "    'optimism': 'optimism',\n",
        "    'pride': 'pride',\n",
        "    'realization': 'realization',\n",
        "    'relief': 'relief',\n",
        "    'remorse': 'remorse',\n",
        "    'sadness': 'sadness',\n",
        "    'surprise': 'surprise',\n",
        "    'neutral': 'neutral',\n",
        "}"
      ],
      "metadata": {
        "id": "tnJFjwKOT999"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "fWa7g2prUBU5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "i7dqLrVuUNgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "RxkNzuoHUPn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yikyaks = pd.read_csv('/content/database.csv')"
      ],
      "metadata": {
        "id": "dOtUbrsXUT92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yikyaks"
      ],
      "metadata": {
        "id": "TNG4js31G_rx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yikyaks.iloc[:, 0] = yikyaks.iloc[:, 0]"
      ],
      "metadata": {
        "id": "sNWRHCtkUV8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_data = yikyaks.groupby(yikyaks.iloc[:, 0])"
      ],
      "metadata": {
        "id": "NORhYfTEUYz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib"
      ],
      "metadata": {
        "id": "RKEEYemSUbHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "osIhVxftUc5o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.cm import get_cmap"
      ],
      "metadata": {
        "id": "NkPZGQawUgcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "eA7bXLV-fVLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "61SySN3Tgy2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PREDICT_TEXT = [\n",
        "  b'Good for you!',\n",
        "  b'Happy birthday!',\n",
        "  b'I love you.',\n",
        "]"
      ],
      "metadata": {
        "id": "YuQ5jxyVzq6s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "model = build_model(base_layers.PREDICT)\n",
        "model.load_weights('model/model_checkpoint')\n",
        "\n",
        "for text in PREDICT_TEXT:\n",
        "  results = model.predict(x=[text])\n",
        "  print('')\n",
        "  print('{}:'.format(text))\n",
        "  labels = np.flip(np.argsort(results[0]))\n",
        "  for x in range(3):\n",
        "    label = LABELS[labels[x]]\n",
        "    label = EMOTION_MAP[label] if EMOTION_MAP[label] else label\n",
        "    print('{}: {}'.format(label, results[0][labels[x]]))"
      ],
      "metadata": {
        "id": "cBHNOB_80fMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "\n",
        "for date, group in grouped_data:\n",
        "    print('Date: {}'.format(date))\n",
        "\n",
        "    emotion_totals = {emotion: 0.0 for emotion in LABELS}\n",
        "    total_emotions = {emotion: 0.0 for emotion in LABELS}\n",
        "\n",
        "    for index, row in group.iterrows():\n",
        "        print(row[1])\n",
        "        results = model.predict(x=[row[1]])\n",
        "        print('')\n",
        "        print('{}:'.format(row[1]))\n",
        "        labels = np.flip(np.argsort(results[0]))\n",
        "\n",
        "        neutral = False\n",
        "\n",
        "        for x in range(3):\n",
        "            label = LABELS[labels[x]]\n",
        "            if (x == 0):\n",
        "              if label == 'neutral':\n",
        "                neutral = True\n",
        "              else:\n",
        "                emotion_totals[label] += 1\n",
        "            if (x == 1 and neutral):\n",
        "              emotion_totals[label] += 1\n",
        "            total_emotions[label] += results[0][labels[x]]\n",
        "            print('{}: {}'.format(label, results[0][labels[x]]))\n",
        "\n",
        "    top_emotion = max(emotion_totals, key=emotion_totals.get)\n",
        "    print('Top Emotion: {} ({:.2%})'.format(top_emotion, emotion_totals[top_emotion]))\n",
        "\n",
        "    df_plot = pd.DataFrame([emotion_totals], index=[date])\n",
        "    dfs.append(df_plot)\n",
        "\n",
        "df_combined = pd.concat(dfs)\n",
        "\n",
        "cmap = get_cmap('tab20')\n",
        "colors = [cmap(i) for i in np.linspace(0, 1, len(LABELS))]\n",
        "\n",
        "ax = df_combined.plot(kind='bar', stacked=True, color=colors)\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Emotion Frequency')\n",
        "plt.title('YikYak Emotion Distribution Per Day')\n",
        "\n",
        "# Customize the legend with unique colors\n",
        "handles, labels = ax.get_legend_handles_labels()\n",
        "ax.legend(handles, labels, title='Emotion', bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "XoQV3tpfUkEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_data = pd.read_csv('/content/LabeledData-dates.csv')"
      ],
      "metadata": {
        "id": "v8rswPiQ52en"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labeled_data"
      ],
      "metadata": {
        "id": "s1iChgzp6FYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = labeled_data.groupby('Date')"
      ],
      "metadata": {
        "id": "OBmoMWr48Pjg"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib.cm import get_cmap\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "T-sEtga9JyjG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "dfs_yikyaks = []\n",
        "\n",
        "for date, group in grouped:\n",
        "  print(date)\n",
        "    # Check if the group is not empty\n",
        "  if not group.empty:\n",
        "      emotions = {emotion: 0.0 for emotion in LABELS}\n",
        "\n",
        "      for index, row in group.iterrows():\n",
        "        emotions[row['Emotion Detected']] += 1\n",
        "\n",
        "      print(emotions)\n",
        "\n",
        "      df_plot = pd.DataFrame([emotions], index=[date])\n",
        "      dfs_yikyaks.append(df_plot)\n",
        "\n",
        "print(dfs_yikyaks)\n",
        "\n",
        "# Check if there are DataFrames in the list before concatenating\n",
        "if dfs_yikyaks:\n",
        "    df_comb = pd.concat(dfs_yikyaks)\n",
        "\n",
        "    cmap = get_cmap('tab20')\n",
        "    colors = [cmap(i) for i in np.linspace(0, 1, len(LABELS))]\n",
        "\n",
        "    ax_2 = df_comb.plot(kind='bar', stacked=True, color=colors, width=0.8)\n",
        "\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Emotion Frequency')\n",
        "    plt.title('YikYak Emotion Distribution Per Day')\n",
        "\n",
        "    handles, labels = ax_2.get_legend_handles_labels()\n",
        "    ax_2.legend(handles, labels, title='Emotion', bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)\n",
        "\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No data to plot.\")"
      ],
      "metadata": {
        "id": "a0guP59B8pZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}